{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a555f6ec",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f18722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "\n",
    "\n",
    "llm_model = \"gpt-4.1-nano\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ebe023d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('assets/Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba295f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c72cca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=llm_model,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93dadca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some creative and catchy company name ideas for a colorful sock brand:\n",
      "\n",
      "1. **Sock Spectrum**  \n",
      "2. **ColorPop Socks**  \n",
      "3. **Vivid Toes**  \n",
      "4. **Rainbow Steps**  \n",
      "5. **BrightStride**  \n",
      "6. **Chromatic Socks**  \n",
      "7. **Hue & Sole**  \n",
      "8. **ColorSplash Socks**  \n",
      "9. **KaleidoSocks**  \n",
      "10. **Prism Socks**  \n",
      "\n",
      "When choosing the best name, consider factors like uniqueness, availability of domain names, and how well it reflects your brandâ€™s personality.\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best company name for a company that makes {product}?\"\n",
    ")\n",
    "# Create a chain\n",
    "chain = prompt | model | StrOutputParser()\n",
    "# Test the chain\n",
    "result = chain.invoke({\"product\": \"colorful socks\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f987388e",
   "metadata": {},
   "source": [
    "### Sequential Chains (Single Input â†’ Single Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2039cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Suggest a company name for a business that makes {product}.\"\n",
    ")\n",
    "\n",
    "name_chain = name_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "226857cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20-word description for a company called {company_name}.\"\n",
    ")\n",
    "\n",
    "description_chain = description_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9780c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "overall_chain = (\n",
    "    name_chain\n",
    "    | RunnableLambda(lambda name: {\"company_name\": name})\n",
    "    | description_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb5d4516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Sure! offers luxurious, regal queen-size sheet sets designed for ultimate comfort and elegant sleep experiences.\n"
     ]
    }
   ],
   "source": [
    "result = overall_chain.invoke({\"product\": \"queen-size sheet set\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2993d7",
   "metadata": {},
   "source": [
    "### 3ï¸âƒ£ Multi-Input / Multi-Output Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0609172",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate this review to English:\\n\\n{review}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc31fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize this review in one sentence:\\n\\n{english_review}\"\n",
    ")\n",
    "\n",
    "summary_chain = summary_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01a2985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is this review written in?\\n\\n{review}\"\n",
    ")\n",
    "\n",
    "language_chain = language_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f43acb",
   "metadata": {},
   "source": [
    "Run multiple chains in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "initial_step = RunnableParallel(\n",
    "    english_review=translate_chain,\n",
    "    language=language_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311234d",
   "metadata": {},
   "source": [
    "Add summary step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0499e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english_review': \"I find the taste mediocre. The foam doesn't hold, it's strange. I buy the same ones from stores and the flavor is much better... Old batch or counterfeit!?\", 'language': 'The review is written in French.', 'summary': 'The reviewer finds the taste mediocre and the foam unsatisfactory, suspecting it may be an old or counterfeit batch compared to store-bought versions.'}\n"
     ]
    }
   ],
   "source": [
    "full_chain = (\n",
    "    initial_step\n",
    "    | RunnableParallel(\n",
    "        english_review=itemgetter(\"english_review\"),\n",
    "        language=itemgetter(\"language\"),\n",
    "        summary=summary_chain\n",
    "    )\n",
    ")\n",
    "result = full_chain.invoke({\"review\": df.Review[5]})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56ae7f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je vous remercie pour votre retour. Il est regrettable que la saveur et la mousse nâ€™aient pas Ã©tÃ© Ã  la hauteur de vos attentes. Nous prenons ces remarques trÃ¨s au sÃ©rieux et allons immÃ©diatement vÃ©rifier la qualitÃ© de nos fournisseurs pour nous assurer de la fraÃ®cheur et de lâ€™authenticitÃ© de nos produits. Nous espÃ©rons pouvoir amÃ©liorer notre offre et vous satisfaire lors de votre prochaine visite.\n"
     ]
    }
   ],
   "source": [
    "followup_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow-up response to this summary in {language}:\\n\\n{summary}\"\n",
    ")\n",
    "\n",
    "followup_chain = followup_prompt | model | StrOutputParser()\n",
    "\n",
    "final_chain = full_chain | followup_chain\n",
    "result = final_chain.invoke({\"review\": df.Review[5]})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac852b1",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7068172",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_chain = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"PHYSICS CHAIN\\nYou are a physics expert. Answer this question:\\n{question}\"\n",
    "    )\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "math_chain = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"MATH CHAIN\\nYou are a math expert. Answer this question:\\n{question}\"\n",
    "    )\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "general_chain = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"GENERAL CHAIN\\nYou are a 2 year old childAnswer this question:\\n{question}\"\n",
    "    )\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab38aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# simple routing using string matching\n",
    "simple_router = RunnableBranch(\n",
    "    (lambda x: \"physics\" in x[\"question\"].lower(), physics_chain),\n",
    "    (lambda x: \"integral\" in x[\"question\"].lower(), math_chain),\n",
    "    general_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca7a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hmm, blackbody radiation is when things get really hot and they give off light all by themselves, like the sun or a hot stove!'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_router.invoke({\"question\": \"What is blackbody radiation?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b360e92",
   "metadata": {},
   "source": [
    "#### Routing using a classifer for the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3b83ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a classifier that can classify the question into one of the following categories:\n",
    "# - physics\n",
    "# - math\n",
    "# - general\n",
    "# The classifier should return the category name.\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "classifier_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Classify the question into exactly one category: physics, math, or general. Reply with only that single word.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "classifier_chain = classifier_prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "def _normalize(s):\n",
    "    raw = (s or \"\").strip()\n",
    "    category = raw.lower().split()[0] if raw else \"general\"\n",
    "    print(f\"ðŸš€ [classifier] selected category: {category}\")\n",
    "    return category\n",
    "\n",
    "\n",
    "# Single Runnable: input -> input with \"category\" set (physics|math|general).\n",
    "# Run this before RunnableBranch so conditions read category without re-invoking the LLM.\n",
    "classifier_runnable = (\n",
    "    RunnablePassthrough.assign(\n",
    "        category=classifier_chain | RunnableLambda(_normalize)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Router: classifier_runnable runs once; RunnableBranch conditions use x[\"category\"]\n",
    "classifier_router = classifier_runnable | RunnableBranch(\n",
    "    (lambda x: x.get(\"category\") == \"physics\", physics_chain),\n",
    "    (lambda x: x.get(\"category\") == \"math\", math_chain),\n",
    "    general_chain,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a7eba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackbody radiation refers to the electromagnetic radiation emitted by an idealized object known as a blackbody, which absorbs all incident radiation regardless of frequency or angle. When a blackbody is heated to a certain temperature, it emits a characteristic spectrum of radiation that depends solely on its temperature, not on its material composition. \n",
      "\n",
      "The spectrum of blackbody radiation has a distinct shape: it peaks at a wavelength inversely proportional to the temperature (according to Wien's displacement law) and its intensity distribution follows the Planck radiation law. This concept was crucial in resolving the ultraviolet catastrophe predicted by classical physics and led to the development of quantum theory, as Planck introduced quantization of energy to accurately describe the observed spectrum. \n",
      "\n",
      "In essence, blackbody radiation provides a foundational understanding of how objects emit electromagnetic energy due to their temperature, serving as a cornerstone in thermodynamics, quantum mechanics, and astrophysics.\n"
     ]
    }
   ],
   "source": [
    "result = classifier_router.invoke({\"question\": \"What is blackbody radiation?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "670ff9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ [classifier] selected category: general\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Photosynthesis is when plants use sunlight to make their food. They take in sunlight, water, and air, and turn it into something they can eat to grow.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_router.invoke({\"question\": \"What is photosynthesis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "627047da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ [classifier] selected category: general\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Polygamy is when someone has more than one husband or wife at the same time.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_router.invoke({\"question\": \"What is polygamy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b9a8b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ [classifier] selected category: math\n",
      "Probability theory is a branch of mathematics that deals with analyzing and modeling uncertainty and randomness. It provides a formal framework for quantifying the likelihood of different events occurring.\n",
      "\n",
      "**Key Concepts in Probability Theory:**\n",
      "\n",
      "1. **Sample Space (Î©):** The set of all possible outcomes of a random experiment. For example, when rolling a die, the sample space is {1, 2, 3, 4, 5, 6}.\n",
      "\n",
      "2. **Events:** Subsets of the sample space. An event could be \"rolling an even number,\" which corresponds to {2, 4, 6}.\n",
      "\n",
      "3. **Probability Measure (P):** A function that assigns a number between 0 and 1 to each event, representing the likelihood of that event. The probability of the entire sample space is 1, indicating certainty.\n",
      "\n",
      "4. **Basic Axioms of Probability:**\n",
      "   - Non-negativity: \\( P(A) \\geq 0 \\) for any event \\( A \\).\n",
      "   - Normalization: \\( P(Î©) = 1 \\).\n",
      "   - Additivity: For mutually exclusive events \\( A \\) and \\( B \\), \\( P(A \\cup B) = P(A) + P(B) \\).\n",
      "\n",
      "5. **Conditional Probability:** The probability of an event \\( A \\) given that another event \\( B \\) has occurred, denoted \\( P(A|B) \\), calculated as:\n",
      "   \\[\n",
      "   P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\quad \\text{(provided } P(B) > 0 \\text{)}.\n",
      "   \\]\n",
      "\n",
      "6. **Independent Events:** Two events \\( A \\) and \\( B \\) are independent if:\n",
      "   \\[\n",
      "   P(A \\cap B) = P(A) \\times P(B).\n",
      "   \\]\n",
      "\n",
      "7. **Bayes' Theorem:** A way to update probabilities based on new information:\n",
      "   \\[\n",
      "   P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}.\n",
      "   \\]\n",
      "\n",
      "**Applications of Probability Theory:**\n",
      "\n",
      "- Predicting outcomes in games and gambling.\n",
      "- Risk assessment in finance and insurance.\n",
      "- Statistical inference and data analysis.\n",
      "- Machine learning algorithms.\n",
      "\n",
      "In summary, probability theory provides the tools and principles to analyze situations involving uncertainty, enabling us to make informed predictions and decisions based on incomplete or random data.\n"
     ]
    }
   ],
   "source": [
    "result = classifier_router.invoke({\"question\": \"Explain probability theory\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
